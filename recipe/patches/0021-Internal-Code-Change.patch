From 8b44cf62d11d718b7568e26a00475b407b3c733d Mon Sep 17 00:00:00 2001
From: Brian Wieder <bwieder@google.com>
Date: Fri, 28 Apr 2023 13:52:53 -0700
Subject: [PATCH 21/30] Internal Code Change

PiperOrigin-RevId: 527978155
Change-Id: I324377be8f71a6e5d500440eb6704ca39dbfa800
---
 tf_slim/data/parallel_reader.py |  5 +++--
 tf_slim/evaluation_test.py      |  5 ++---
 tf_slim/summaries_test.py       |  5 ++---
 tf_slim/training/training.py    | 11 +++++++----
 4 files changed, 14 insertions(+), 12 deletions(-)

diff --git a/tf_slim/data/parallel_reader.py b/tf_slim/data/parallel_reader.py
index 98ee36b..d197d12 100644
--- a/tf_slim/data/parallel_reader.py
+++ b/tf_slim/data/parallel_reader.py
@@ -19,13 +19,14 @@ from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
+import tensorflow as tf
+
 # pylint:disable=g-direct-tensorflow-import
 from tensorflow.python.framework import dtypes as tf_dtypes
 from tensorflow.python.framework import ops
 from tensorflow.python.ops import data_flow_ops
 from tensorflow.python.ops import io_ops
 from tensorflow.python.ops import math_ops
-from tensorflow.python.platform import gfile
 from tensorflow.python.summary import summary
 from tensorflow.python.training import input as tf_input
 from tensorflow.python.training import queue_runner
@@ -312,7 +313,7 @@ def get_data_files(data_sources):
       data_files += get_data_files(source)
   else:
     if '*' in data_sources or '?' in data_sources or '[' in data_sources:
-      data_files = gfile.Glob(data_sources)
+      data_files = tf.compat.v1.gfile.Glob(data_sources)
     else:
       data_files = [data_sources]
   if not data_files:
diff --git a/tf_slim/evaluation_test.py b/tf_slim/evaluation_test.py
index 7b24b87..6ae1276 100644
--- a/tf_slim/evaluation_test.py
+++ b/tf_slim/evaluation_test.py
@@ -43,7 +43,6 @@ from tensorflow.python.ops import math_ops
 from tensorflow.python.ops import metrics
 from tensorflow.python.ops import variables
 from tensorflow.python.platform import flags
-from tensorflow.python.platform import gfile
 from tensorflow.python.platform import test
 from tensorflow.python.summary import summary_iterator
 from tensorflow.python.training import input  # pylint: disable=redefined-builtin
@@ -214,9 +213,9 @@ class EvaluationTest(test.TestCase):
                                      variables.local_variables_initializer())
     # Create checkpoint and log directories:
     chkpt_dir = tempfile.mkdtemp('tmp_logs')
-    gfile.MakeDirs(chkpt_dir)
+    tf.gfile.MakeDirs(chkpt_dir)
     logdir = tempfile.mkdtemp('tmp_logs2')
-    gfile.MakeDirs(logdir)
+    tf.gfile.MakeDirs(logdir)
 
     # Save initialized variables to a checkpoint directory:
     saver = saver_lib.Saver()
diff --git a/tf_slim/summaries_test.py b/tf_slim/summaries_test.py
index f7cdb72..5dd91b5 100644
--- a/tf_slim/summaries_test.py
+++ b/tf_slim/summaries_test.py
@@ -28,7 +28,6 @@ from tf_slim import summaries
 # pylint:disable=g-direct-tensorflow-import
 from tensorflow.python.framework import ops
 from tensorflow.python.ops import array_ops
-from tensorflow.python.platform import test
 from tensorflow.python.summary import summary
 from tensorflow.python.summary import summary_iterator
 # pylint:enable=g-direct-tensorflow-import
@@ -38,7 +37,7 @@ def setUpModule():
   tf.disable_eager_execution()
 
 
-class SummariesTest(test.TestCase):
+class SummariesTest(tf.test.TestCase):
 
   def assert_scalar_summary(self, output_dir, names_to_values):
     """Asserts that the given output directory contains written summaries.
@@ -104,4 +103,4 @@ class SummariesTest(test.TestCase):
 
 
 if __name__ == '__main__':
-  test.main()
+  tf.test.main()
diff --git a/tf_slim/training/training.py b/tf_slim/training/training.py
index 1ece335..b4884a7 100644
--- a/tf_slim/training/training.py
+++ b/tf_slim/training/training.py
@@ -246,6 +246,8 @@ from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
+import tensorflow as tf
+
 # pylint: disable=g-direct-tensorflow-import
 
 from tensorflow.python.framework import indexed_slices
@@ -254,7 +256,6 @@ from tensorflow.python.ops import array_ops
 from tensorflow.python.ops import clip_ops
 from tensorflow.python.ops import control_flow_ops
 from tensorflow.python.ops import variables as tf_variables
-from tensorflow.python.platform import tf_logging as logging
 from tensorflow.python.summary import summary
 from tensorflow.python.training import monitored_session
 from tensorflow.python.training import optimizer as tf_optimizer
@@ -293,7 +294,7 @@ def add_gradients_summaries(grads_and_vars):
           summary.scalar(var.op.name + '_gradient_norm',
                          clip_ops.global_norm([grad_values])))
     else:
-      logging.info('Var %s has no gradient', var.op.name)
+      tf.compat.v1.logging.info('Var %s has no gradient', var.op.name)
 
   return summaries
 
@@ -423,8 +424,10 @@ def create_train_op(total_loss,
   else:
     update_ops = set(update_ops)
   if not global_update_ops.issubset(update_ops):
-    logging.warning('update_ops in create_train_op does not contain all the '
-                    'update_ops in GraphKeys.UPDATE_OPS')
+    tf.compat.v1.logging.warning(
+        'update_ops in create_train_op does not contain all the '
+        'update_ops in GraphKeys.UPDATE_OPS'
+    )
 
   # Make sure update_ops are computed before total_loss.
   if update_ops:
-- 
2.40.1

