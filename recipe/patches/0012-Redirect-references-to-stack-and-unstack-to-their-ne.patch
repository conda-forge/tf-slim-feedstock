From 0171d4be874f8bc89fb9532eca5b12ac97e5a31e Mon Sep 17 00:00:00 2001
From: Juan Martinez Castellanos <juanantoniomc@google.com>
Date: Fri, 24 Feb 2023 11:58:05 -0800
Subject: [PATCH 12/30] Redirect references to `stack` and `unstack` to their
 new location in `array_ops_stack.py`.

This is to ultimately remove the circular dependency between `array_ops.py` and `sparse_tensor.py`.

PiperOrigin-RevId: 512128147
Change-Id: Ic85522f652af988e4da2c5d9dc6749e437cff86c
---
 tf_slim/data/tfexample_decoder.py | 5 +++--
 tf_slim/layers/layers.py          | 5 +++--
 tf_slim/metrics/metric_ops.py     | 7 ++++---
 3 files changed, 10 insertions(+), 7 deletions(-)

diff --git a/tf_slim/data/tfexample_decoder.py b/tf_slim/data/tfexample_decoder.py
index c5df47e..7d4dc0b 100644
--- a/tf_slim/data/tfexample_decoder.py
+++ b/tf_slim/data/tfexample_decoder.py
@@ -34,6 +34,7 @@ from tensorflow.python.framework import dtypes
 from tensorflow.python.framework import ops
 from tensorflow.python.framework import sparse_tensor
 from tensorflow.python.ops import array_ops
+from tensorflow.python.ops import array_ops_stack
 from tensorflow.python.ops import check_ops
 from tensorflow.python.ops import control_flow_ops
 from tensorflow.python.ops import image_ops
@@ -200,7 +201,7 @@ class Tensor(ItemHandler):
         if isinstance(shape_dim, sparse_tensor.SparseTensor):
           shape_dim = sparse_ops.sparse_tensor_to_dense(shape_dim)
         shape_dims.append(shape_dim)
-      shape = array_ops.reshape(array_ops.stack(shape_dims), [-1])
+      shape = array_ops.reshape(array_ops_stack.stack(shape_dims), [-1])
     if isinstance(tensor, sparse_tensor.SparseTensor):
       if shape is not None:
         tensor = sparse_ops.sparse_reshape(tensor, shape)
@@ -334,7 +335,7 @@ class SparseTensor(ItemHandler):
     rank = indices_shape[1]
     ids = math_ops.cast(indices.values, dtypes.int64)
     indices_columns_to_preserve = array_ops.slice(
-        indices.indices, [0, 0], array_ops.stack([-1, rank - 1]))
+        indices.indices, [0, 0], array_ops_stack.stack([-1, rank - 1]))
     new_indices = array_ops.concat(
         [indices_columns_to_preserve, array_ops.reshape(ids, [-1, 1])], 1)
 
diff --git a/tf_slim/layers/layers.py b/tf_slim/layers/layers.py
index f8cb8e9..c91cc1d 100644
--- a/tf_slim/layers/layers.py
+++ b/tf_slim/layers/layers.py
@@ -37,6 +37,7 @@ from tensorflow.python.framework import ops
 from tensorflow.python.framework import sparse_tensor
 from tensorflow.python.framework import tensor_shape
 from tensorflow.python.ops import array_ops
+from tensorflow.python.ops import array_ops_stack  # pylint: disable=g-direct-tensorflow-import
 from tensorflow.python.ops import check_ops
 from tensorflow.python.ops import custom_gradient
 from tensorflow.python.ops import init_ops
@@ -3317,10 +3318,10 @@ def legacy_fully_connected(x,
       y = nn.bias_add(y, b)
 
     if len(dims) > 2:
-      out_shape = array_ops.unstack(array_ops.shape(x))
+      out_shape = array_ops_stack.unstack(array_ops.shape(x))
       out_shape[-1] = num_output_units
 
-      y = array_ops.reshape(y, array_ops.stack(out_shape))
+      y = array_ops.reshape(y, array_ops_stack.stack(out_shape))
 
       static_shape = x.get_shape().as_list()
       static_shape[-1] = num_output_units
diff --git a/tf_slim/metrics/metric_ops.py b/tf_slim/metrics/metric_ops.py
index cdd844c..d87afb3 100644
--- a/tf_slim/metrics/metric_ops.py
+++ b/tf_slim/metrics/metric_ops.py
@@ -26,6 +26,7 @@ import tensorflow.compat.v1 as tf
 from tensorflow.python.framework import dtypes
 from tensorflow.python.framework import ops
 from tensorflow.python.ops import array_ops
+from tensorflow.python.ops import array_ops_stack  # pylint: disable=g-direct-tensorflow-import
 from tensorflow.python.ops import check_ops
 from tensorflow.python.ops import confusion_matrix
 from tensorflow.python.ops import control_flow_ops
@@ -748,7 +749,7 @@ def _streaming_confusion_matrix_at_thresholds(predictions,
     num_predictions = array_ops.shape(predictions_2d)[0]
   thresh_tiled = array_ops.tile(
       array_ops.expand_dims(array_ops.constant(thresholds), [1]),
-      array_ops.stack([1, num_predictions]))
+      array_ops_stack.stack([1, num_predictions]))
 
   # Tile the predictions after thresholding them across different thresholds.
   pred_is_pos = math_ops.greater(
@@ -947,7 +948,7 @@ def streaming_curve_points(labels=None,
 
     xs, ys = compute_points(values['tp'], values['fn'], values['tn'],
                             values['fp'])
-    points = array_ops.stack([xs, ys], axis=1)
+    points = array_ops_stack.stack([xs, ys], axis=1)
     update_op = control_flow_ops.group(*update_ops.values())
 
     if metrics_collections:
@@ -3629,7 +3630,7 @@ def streaming_concat(values,
     def reallocate():
       """Reallocates the varible to the next size."""
       next_size = _next_array_size(new_size)
-      next_shape = array_ops.stack([next_size] + fixed_shape)
+      next_shape = array_ops_stack.stack([next_size] + fixed_shape)
       new_value = array_ops.zeros(next_shape, dtype=values.dtype)
       old_value = array.value()
       with ops.control_dependencies([old_value]):
-- 
2.40.1

